<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
<!-- MathJax scripts -->
<!--
  <script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
-->
<!--
<script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
<script type="text/javascript">
LatexIT.add('p',true);
</script>
-->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js">
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full"></script>


<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Project 2: Na&iuml;ve Bayes</title>
<link href="projects.css" rel="stylesheet" type="text/css">
</head>

<body>
<h2>Project 2: Na&iuml;ve Bayes</h2>


<!--announcements-->
<blockquote>
    <center>
    <img src="nb.png" width="200px" />
    </center>
      <p><cite><center>"All models are wrong, but some are useful."<br>
       -- George E.P. Box
      </center></cite></p>
</blockquote>

<h3>Introduction</h3>
<!--AÃ°albrandr-->

<p>A&eth;albrandr is visiting St. Louis from Norway and has been having the hardest time distinguishing boys and girls because of the weird American names like Jack and Jane.  This has been causing lots of problems for A&eth;albrandr when he goes on dates. When he heard that Washington University has a Machine Learning class, he asked that we help him identify the gender of a person based on their name to the best of our ability.  In this project, you will implement Na&iuml;ve Bayes to predict if a name is male or female. But before you get started, you need to create a GitHub Classroom team and clone the project2 repository. </p>



<table border="0" cellpadding="10">
  <tr><td colspan="2"><b>Files you'll edit:</b>
</td></tr>

<p>The code for this project (<code>project2</code>) consists of several files, some of which you will need to read and understand in order to complete the assignment, and some of which you can ignore.


<!---<tr><td><code>  <font color="red">codename.txt</font></code></td><td>This file contains your codename that represents you on the leaderboard. You can change your codename anytime you want, but please avoid offensive or annoying names (e.g. no names of other class mates, no swear words, no inappropriate body parts, javascripts,...) </td></tr> -->

<tr><td><code>  naivebayesPXY.py</code></td><td>Computes P(X|Y)</td></tr>
<tr><td><code>  naivebayesPY.py</code></td><td>Computes P(Y)</td></tr>
<tr><td><code>  naivebayes.py</code></td><td>Computes log probability log P(Y|X = x1)</td></tr>
<tr><td><code>  naivebayesCL.py</code></td><td>Turns the Na&iuml;ve Bayes output into a linear classifier</td></tr>
<tr><td><code>  classifyLinear.py</code></td><td>Makes predictions with a linear classifier.</td></tr>

  <tr><td colspan="2"><b>Files you might want to look at:</b></td></tr>
<tr><td><code>  name2features.py</code></td><td>Converts a name to a feature vector.  You do not need to edit this, but you may want to!</td></tr>
<tr><td><code>  genTrainFeatures.py</code></td><td>Calls name2features.py.</td></tr>
<tr><td><code>  whoareyou.py</code></td><td>Allows you to test your linear classifier interactively.</td></tr>
<tr><td><code>  example_tests.py</code></td><td>Describes several unit tests to find obvious bugs in your implementation.</td></tr>
<tr><td><code>  boys.train</code></td><td>The training examples for boys names.</td></tr>
<tr><td><code>  girls.train</code></td><td>The training examples for girls names.</td></tr>



</table>
<p><strong>How to submit:</strong>  You can commit your code through the command line with git and submit on Gradescope either in a zip file or through Github. If the project is submitted before the initial deadline passes, you will receive information and a score for the performance evaluation (only once the deadline is reached).
However, the autograder will not reveal any information on how your code performed for any projects submitted during the three day extension period. You can submit your project as many times as you want but the final submission score will count for your grade. If you submitted by the initial deadline and would like to improve your performance score, you can submit again during the extension period.<br>


<p><strong>Grading:</strong> Your code will be autograded for technical
correctness. Please <em>do not</em> change the names of any provided functions or classes within the code, or you will wreak havoc on the autograder. However, the correctness of your implementation -- not the autograder's output -- will be the final judge of your score.  If necessary, we will review and grade assignments individually to ensure that you receive due credit for your work.</p>

<p><strong>PYTHON Version in Autograder:</strong> The autograder uses PYTHON 3.6. To rule out any incompatabilites of differnt versions we recommend to use any version of PYTHON 3.6 or newer for the implementation projects.

<p><strong>Regrade Requets:</strong> Use Gradescope for regrade requests.
</p>

<p><strong>Academic Dishonesty:</strong> We will be checking your code against other submissions in the class for logical redundancy. If you copy someone else's code and submit it with minor changes, we will know. These cheat detectors are quite hard to fool, so please don't try. We trust you all to submit your own work only; <em>please</em> don't let us down. If you do, we will pursue the strongest consequences available to us.

<p><strong>Getting Help:</strong> You are not alone!  If you find yourself stuck  on something, contact the course TAs for help.  Office hours and <a href="https://piazza.com/">Piazza</a> are there for your
support; please use them.  If you can't make our office hours, let us know and we will schedule more.  We want these projects to be rewarding and instructional, not frustrating and demoralizing.  But, we don't know when or how to help unless you ask.


<h3> Of boys and girls </h3>

<p> Take a look at the files <code>girls.train</code> and <code>boys.train</code>. For example with the unix command <pre>cat girls.train</pre>
<pre>
...
Addisyn
Danika
Emilee
Aurora
Julianna
Sophia
Kaylyn
Litzy
Hadassah
</pre>
Believe it or not, these are all more or less common girl names. The problem with the current file is that the names are in plain text, which makes it hard for a machine learning algorithm to do anything useful with them. We therefore need to transform them into some vector format, where each name becomes a vector that represents a point in some high dimensional input space. </p>
<p><code>name2features.py</code>  reads a name, for example one in <code>girls.train</code> (or in <code>boys.train</code>) and converts it into a 128-dimensional feature vector.
Can you figure out what the features are? (Understanding how these features are constructed will help you later on in the competition.)<br></p>

<p>We have provided you with a Python function <code>genTrainFeatures.py</code>, which calls this Python script, transforms the names into features and loads them into Python. You can call
<pre>[x,y]=genTrainFeatures()</pre> to load in the features and the labels of all boys and girls names.



<h3> The Na&iuml;ve Bayes Classifier </h3>

<p> The Na&iuml;ve Bayes classifier is a linear classifier based on Bayes Rule. The following questions will ask you to finish these functions in a pre-defined order. <br>
<strong>Remember: as a general rule, you should avoid tight loops at all cost.</strong></p>
<p>(a) Estimate the class probability P(Y) in
<b><code>naivebayesPY.py</code></b>
. This should return the probability that a sample in the training set is positive or negative, independent of its features.
</p>
<p>(b) Estimate the conditional probabilities P(X|Y) in
<b><code>naivebayesPXY.py</code></b>
.  Use a <b>categorical</b> distribution as model. This will return the probability vectors  for all features given a class label.
</p>
<p>(c) Solve for the log ratio, $\log\left(\frac{P(Y=1 | X)}{P(Y=-1|X)}\right)$, using Bayes Rule.
 Implement this in
<b><code>naivebayes.py</code></b>.
</p>
<p>(d) Na&iuml;ve Bayes can also be written as a linear classifier.  Implement this in
<b><code>naivebayesCL.py</code></b>
</p>
<p>(e) Implement
<b><code>classifyLinear.py</code></b>
 that applies a linear weight vector and bias to a set of input vectors and outputs their predictions.  (You can use your answer from the previous project.)
You can now test your training error with
<pre>
>> [x,y]=genTrainFeatures();
>> [w,b]=naivebayesCL(x,y);
>> preds=classifyLinear(x,w,b);
>> trainingerror=np.sum(preds~=y)/(y.shape[1])
trainingerror =  0.XX...
</pre>
 </p>





<!--announcements-->
Once your Na&iuml;ve Bayes code is implemented, you can try the function <b><code>whoareyou.py</code></b> to test names interactively. <br><br>

In a script: <br><br>
<code>

xTr,yTr = genTrainFeatures() <br>
w,b = naivebayesCL(xTr,yTr) <br>
whoareyou(w,b) <br> <br>

</code>

In the terminal: <br><br>
<code>
Who are you>David<br>
David, I am sure you are a nice boy.<br>
Who are you>Anne<br>
Anne, I am sure you are a nice girl.<br>
Who are you>byebye<br>
</code>


<h3>Hints</h3>
<p><strong>Tests.</strong> To test your code you can run <code>example_tests.py</code>, which describes and partially implements  several unit tests. Feel free to implement your own tests to better debug and test your implementation. Those tests are a subset of what we will use in the audograder to grade your submission.</p>


<p>70% of the grade for your project2 submission will be assigned based on the correctness of your implementation. </p>

<h3> Feature Extraction (Quality Evaluation)</h3>
30% of the grade for your project2 submission will be assigned by how well your classifier performs on a secret test set. If you want to improve your classifier modify <code>name2features.py</code>. The autograder will use your Python script to extract features and train your classifier on the names training set.



<hr>
<h5>Credits: Project adapted from Kilian Weinberger (Thanks for sharing!).</h5>

</body>
</html>
